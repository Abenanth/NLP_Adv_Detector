# NLP_Adv_Prompt_Detector
Fine‑tuning DistilBERT and RoBERTa as a hierarchical classifier to intercept and block adversarial prompts before they reach any LLM.

Adapting DistilBERT and RoBERTa into a multi‑level filtering system that prevents adversarial inputs from ever reaching a large language model.

Leveraging fine‑tuned DistilBERT and RoBERTa in a tiered classifier architecture to detect and stop adversarial prompts from passing through to any LLM.

![image](https://github.com/user-attachments/assets/6bf192e6-4246-48b5-9fe8-ee166c8fa4bc)

# Here I used GPT-4 any LLM can be used in a similar way to safegaurd it from JailBreak Attemps. Plus we can always fine-tune the classifiers accordingly.
# Here I used AWS Sagemaker for fine-tuning both DistilBERT and RoBERTa models.

